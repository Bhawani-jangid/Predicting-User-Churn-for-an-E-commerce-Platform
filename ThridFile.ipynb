{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf6b72e5-99a4-4a45-a387-a3762d8ed56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142afd27-4031-4c59-ab15-cc0010e8c005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = \"cleaned_events.csv\"  # Update with your file path\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ea251a9-ef7f-42a3-b67d-a32cab252428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'event_time' is in datetime format\n",
    "df['event_time'] = pd.to_datetime(df['event_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d135e33a-54c6-4bcc-bbcd-d8232b5faeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Dataset Preprocessing\n",
    "# ------------------------------------------------------------------------\n",
    "# Strengths:\n",
    "# - Missing values in category_code, brand, and user_session were handled appropriately by replacing them with \"Unknown\".\n",
    "# - Duplicates were identified and removed.\n",
    "# - event_time was correctly converted to a datetime format for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e670a5-3708-4ba7-8a46-aca17ef640c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvements:\n",
    "# 1. Data Validation:\n",
    "# Check if price contains invalid or extreme outliers, e.g., very high or negative values.\n",
    "df_invalid_prices = df[df['price'] < 0]  # Identify negative prices\n",
    "if not df_invalid_prices.empty:\n",
    "    print(\"Warning: Found negative prices in the dataset!\")\n",
    "    print(df_invalid_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22933dbd-6cff-479e-9840-a9bc112cc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Column Standardization:\n",
    "# Ensure all categorical columns are consistently lowercased to avoid mismatches.\n",
    "df['category_code'] = df['category_code'].str.lower()\n",
    "df['brand'] = df['brand'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72257653-1cae-46af-8c99-233453835c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Enhance Documentation:\n",
    "# Comments added to explain why missing values are handled in a specific way (e.g., \"Unknown\" is used to retain these rows in analysis).\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Exploratory Data Analysis (EDA)\n",
    "# ------------------------------------------------------------------------\n",
    "# Strengths:\n",
    "# - Distribution analysis for event_type, brand, and price was well done with clear visualizations.\n",
    "# - Time-based insights (daily and hourly event distribution) add depth to understanding user activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa14b597-9fdf-4708-88ed-6849f8bc91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvements:\n",
    "# 1. User-Level Insights:\n",
    "# Analyze user behavior over time.\n",
    "user_activity_over_time = df.groupby(['user_id', 'event_date'])['event_type'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2689d4d6-e444-4652-a271-4be5f560ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Event Transitions:\n",
    "# Enhance transition analysis with Sankey diagrams to visualize view -> cart -> purchase flows.\n",
    "# Use pandas.crosstab for a summary.\n",
    "transition_summary = pd.crosstab(df['event_type'], df['event_type'].shift(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f6bd1-7a0a-4cb3-b412-e9ac7c129d3d",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------\n",
    "# Feature Engineering\n",
    "# ------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c7007c4-b524-4884-8dba-70e1fc997e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by user\n",
    "user_group = df.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0126243-e51a-4f9a-8d00-cd97cf697026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhawa\\AppData\\Local\\Temp\\ipykernel_24348\\4163609330.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  recency = user_group.apply(calculate_recency)\n"
     ]
    }
   ],
   "source": [
    "# 1. Recency: Days since the user's last activity\n",
    "def calculate_recency(group):\n",
    "    max_date = group['event_time'].max()\n",
    "    return (df['event_time'].max() - max_date).days\n",
    "\n",
    "recency = user_group.apply(calculate_recency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d440938a-e491-4414-8abb-79b115db51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Frequency: Number of events by user\n",
    "frequency = user_group['event_type'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a550c0ad-4ddc-4e13-b9cc-8edfca3b6076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhawa\\AppData\\Local\\Temp\\ipykernel_24348\\2037841698.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  monetary = user_group.apply(lambda group: group[group['event_type'] == 'purchase']['price'].sum())\n"
     ]
    }
   ],
   "source": [
    "# 3. Monetary: Total spending by user (sum of price for purchase events)\n",
    "monetary = user_group.apply(lambda group: group[group['event_type'] == 'purchase']['price'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "235b69eb-eab4-4560-ba21-3b5893ba7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Session-based features\n",
    "# Calculate number of unique sessions per user\n",
    "sessions_per_user = user_group['user_session'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8865852b-a727-4960-a50a-cd6b6e7a88b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhawa\\AppData\\Local\\Temp\\ipykernel_24348\\1120718153.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  view_to_cart_ratio = user_group.apply(\n"
     ]
    }
   ],
   "source": [
    "# 5. View-to-Cart Ratio\n",
    "view_to_cart_ratio = user_group.apply(\n",
    "    lambda group: group[group['event_type'] == 'cart']['event_type'].count() / max(group[group['event_type'] == 'view']['event_type'].count(), 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51c16bad-33bc-46c1-95c6-eb92de2d9fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhawa\\AppData\\Local\\Temp\\ipykernel_24348\\490721732.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cart_to_purchase_ratio = user_group.apply(\n"
     ]
    }
   ],
   "source": [
    "# 6. Cart-to-Purchase Ratio\n",
    "cart_to_purchase_ratio = user_group.apply(\n",
    "    lambda group: group[group['event_type'] == 'purchase']['event_type'].count() / max(group[group['event_type'] == 'cart']['event_type'].count(), 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3913831f-84a9-4423-859b-3fa30c04bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhawa\\AppData\\Local\\Temp\\ipykernel_24348\\2831324979.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  average_session_duration = user_group.apply(\n"
     ]
    }
   ],
   "source": [
    "# 7. Average Session Duration\n",
    "average_session_duration = user_group.apply(\n",
    "    lambda group: (group['event_time'].max() - group['event_time'].min()).total_seconds() / max(group['user_session'].nunique(), 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f479eb3d-0573-466a-89cc-fee7a5d4d74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Favorite Brand and Category\n",
    "favorite_brand = user_group['brand'].agg(lambda x: x.value_counts().idxmax() if not x.isnull().all() else \"Unknown\")\n",
    "favorite_category = user_group['category_code'].agg(lambda x: x.value_counts().idxmax() if not x.isnull().all() else \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50b74bd9-92ca-47ba-b352-5dae462c7ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into a single DataFrame\n",
    "features = pd.DataFrame({\n",
    "    'user_id': frequency.index,\n",
    "    'recency': recency.values,\n",
    "    'frequency': frequency.values,\n",
    "    'monetary': monetary.values,\n",
    "    'sessions_per_user': sessions_per_user.values,\n",
    "    'view_to_cart_ratio': view_to_cart_ratio.values,\n",
    "    'cart_to_purchase_ratio': cart_to_purchase_ratio.values,\n",
    "    'average_session_duration': average_session_duration.values,\n",
    "    'favorite_brand': favorite_brand.values,\n",
    "    'favorite_category': favorite_category.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60eda519-88f1-4e86-8fda-0c7264243ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN (caused by divisions)\n",
    "features.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 (or other appropriate defaults based on your analysis)\n",
    "features.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab339a0-fb0e-4c20-8d4a-89734825862d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f30a90d7-956b-49e4-9f9a-6967bd107ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Deep Dive into Top Users:\n",
    "# Highlight users with high activity or spending to identify patterns.\n",
    "\n",
    "# ------------------------------------------------------------------------\n",
    "# Feature Engineering\n",
    "# ------------------------------------------------------------------------\n",
    "# Strengths:\n",
    "# - Includes essential features such as recency, frequency, and monetary.\n",
    "# - Behavioral metrics like view_to_cart_ratio and cart_to_purchase_ratio are thoughtful additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c72b062f-8f0c-4a64-bbe1-05f8d337547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvements:\n",
    "# 1. Seasonality Features:\n",
    "# Extract features like month and weekday to capture seasonal trends.\n",
    "df['event_month'] = df['event_time'].dt.month\n",
    "df['event_weekday'] = df['event_time'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eefce668-bc0b-4844-87b7-66e7a4f4a583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete. Here's a preview of normalized features:\n",
      "    recency  frequency  monetary\n",
      "0  0.777070   0.000000       0.0\n",
      "1  0.923567   0.000000       0.0\n",
      "2  0.496815   0.021016       0.0\n",
      "3  0.949045   0.000000       0.0\n",
      "4  0.063694   0.061296       0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "features[['recency', 'frequency', 'monetary']] = scaler.fit_transform(features[['recency', 'frequency', 'monetary']])\n",
    "print(\"Normalization complete. Here's a preview of normalized features:\")\n",
    "print(features[['recency', 'frequency', 'monetary']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddeb739c-59a1-49aa-ace2-4bc2b0e2a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Interactions:\n",
    "# Add interaction terms between features (e.g., sessions_per_user * view_to_cart_ratio) to capture complex patterns.\n",
    "features['interaction'] = features['sessions_per_user'] * features['view_to_cart_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d05d61a9-b32a-4c0a-9261-ac365c608121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engineering Complete. Here's a preview of the features:\n",
      "               user_id   recency  frequency  monetary  sessions_per_user  \\\n",
      "0  1515915625353226922  0.777070   0.000000       0.0                  1   \n",
      "1  1515915625353230067  0.923567   0.000000       0.0                  1   \n",
      "2  1515915625353230683  0.496815   0.021016       0.0                  4   \n",
      "3  1515915625353230922  0.949045   0.000000       0.0                  1   \n",
      "4  1515915625353234047  0.063694   0.061296       0.0                  1   \n",
      "\n",
      "   view_to_cart_ratio  cart_to_purchase_ratio  average_session_duration  \\\n",
      "0                 0.0                     0.0                       0.0   \n",
      "1                 0.0                     0.0                       0.0   \n",
      "2                 0.0                     0.0                  714304.5   \n",
      "3                 0.0                     0.0                       0.0   \n",
      "4                 0.0                     0.0                12244190.0   \n",
      "\n",
      "  favorite_brand                favorite_category  interaction  \n",
      "0          honor               electronics.clocks          0.0  \n",
      "1         kester                          unknown          0.0  \n",
      "2       creative       electronics.audio.acoustic          0.0  \n",
      "3            msi  computers.components.videocards          0.0  \n",
      "4        samsung      electronics.audio.headphone          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the feature DataFrame\n",
    "print(\"Feature Engineering Complete. Here's a preview of the features:\")\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efbc8b89-a4be-46d9-b85d-ebe3be96b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to 'user_features.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the features to a new CSV file\n",
    "features.to_csv(\"user_features.csv\", index=False)\n",
    "print(\"Features saved to 'user_features.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
